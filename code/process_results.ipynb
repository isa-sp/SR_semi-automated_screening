{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415154ba",
   "metadata": {},
   "source": [
    "# Generation of results for the simulation of semi-automated title-abstract screening for systematic reviews of prognosis and intervention studies\n",
    "\n",
    "Isa Spiero <br>\n",
    "\n",
    "#### Part I: Set-up\n",
    "- **1. Import the packages and functions**\n",
    "- **2. Import the intervention and prognsos review datasets** <br>\n",
    "\n",
    "#### Part II: Simulations with original review datasets \n",
    "- **3. Retrieve and merge the output from all simulations** \n",
    "<br>The simulations based on the imported datasets were previously run with a seperate code on a High Performance Computer (HPC). The simulations were run for variations of: the 6 prognosis and 6 intervention review datasets (= 12 datasets + 1 dataset in appendix), 2 feature extraction models + 3 classification models ( = 5 model combinations), and 200 randomly sampled initial training data. This resulted in 13\\*5*200 = 13000 simulations stored in the same number of pickle files (.p). Each of these files consists of a ranking from simulating the semi-automated screening with the respective dataset and modeling methods. All these files are loaded and the output stored for futher processing.\n",
    "- **4. Compute performance metrics from the retrieved simulation output**\n",
    "<br>The retrieved output is then used to calculate the performance metrics (recall, precision at 95% recall, WSS at 95% recall, and nWSS at 95% recall) for each of the simulations.\n",
    "- **5. Create raw tables with all performance metrics seperately** \n",
    "- **6. Process raw tables into pooled tabels (for results)**\n",
    "- **7. Create histograms for WSS and precision (for results)** \n",
    "- **8. Create boxplots/lineplots of increasing recall during screening (for results)** <br>\n",
    "\n",
    "#### Part III: Simulations with adapted review datasets \n",
    "- **9. Variations in number of (relevant) records**\n",
    "- **10. Retrieve and merge the output from all simulations**\n",
    "The simulations using the manually adapted datasets were previously run with a seperate code on a High Performance Computer (HPC). The simulations were run for variations of: the 4 prognosis and 4 intervention datasets manually adapted to contain 2000, 1000, and 500 records of which 50 inclusions ( = 24 manually adapted datasets), 5 samples (seeds) for each manually adapted dataset, 1 feature extraction model + 1 classification model (default models), and 200 randomly sampled initial training data. This resulted in 24\\*5*200 = 24000 simulations stored in the same number of pickle files (.p). Each of these files consists of a ranking from simulating the semi-automated screening with the respective dataset and sampling seed. All these files are loaded and the output stored for futher processing.\n",
    "- **11. Compute performance metrics from the retrieved simulation output**\n",
    "<br>The retrieved output is then used to calculate the performance metrics (recall, precision at 95% recall, WSS at 95% recall, and nWSS at 95% recall) for each of the simulations.\n",
    "- **12. Create raw tables with all performance metrics seperately**\n",
    "- **13. Process raw tables into pooled tables (for results)**\n",
    "- **14. Create histograms for WSS and precision (for results)**\n",
    "- **15. Create lineplots of increasing recall during screening (for results)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b93dc9",
   "metadata": {},
   "source": [
    "## Part I: Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1514387d",
   "metadata": {},
   "source": [
    "### 1. Import the packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d2e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f148a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import compute_metrics\n",
    "from functions import generate_recall_table_prop, max_recall_prop\n",
    "from functions import generate_wss_table, generate_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eac1d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asreview.models.classifiers import LogisticClassifier, LSTMBaseClassifier, LSTMPoolClassifier, NaiveBayesClassifier, NN2LayerClassifier, RandomForestClassifier, SVMClassifier\n",
    "from asreview.models.query import ClusterQuery, MaxQuery, MaxRandomQuery, MaxUncertaintyQuery, RandomQuery, UncertaintyQuery\n",
    "from asreview.models.balance import DoubleBalance, SimpleBalance, UndersampleBalance\n",
    "from asreview.models.feature_extraction import Doc2Vec, EmbeddingIdf, EmbeddingLSTM, SBERT, Tfidf\n",
    "from asreview import open_state\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af186360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ispiero2/Documents/Research/Scripts/Study - Semi-automated screening for SR/GitHub version'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0e78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'data/' \n",
    "path_results_HPC = 'output/simulations_original_datasets/'\n",
    "path_results = 'results/' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ed8ad",
   "metadata": {},
   "source": [
    "### 2. Import the intervention and prognosis review datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0232786",
   "metadata": {},
   "source": [
    "The intervention review datasets that were used for simulation are imported (numbering of the datasets is ordered by authors), and the prognosis review datasets that were used for simulation are imported (numbering of the datasets is ordered by author, so numbers do not correspond to numbers in data prep):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc71797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the review datasets from the dataset-containing folder into a dictionary\n",
    "review_dic = {}\n",
    "\n",
    "for file_name in os.listdir(path_data):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(path_data, file_name)\n",
    "        df = pd.read_excel(file_path)\n",
    "        key = os.path.splitext(file_name)[0].split(\"_\")[0]\n",
    "        review_dic[key] = df\n",
    "\n",
    "review_dic = dict(sorted(review_dic.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11875fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dictionaries for intervention and prognosis review datasets\n",
    "dfs_int = {key: value for key, value in review_dic.items() if key.startswith('Int')}\n",
    "dfs_prog = {key: value for key, value in review_dic.items() if key.startswith('Prog')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a8681",
   "metadata": {},
   "source": [
    "## Part II: Simulations with original review datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26eea5",
   "metadata": {},
   "source": [
    "### 3. Retrieve and merge the output from all simulations\n",
    "\n",
    "To assess the performance of the semi-automated screening tool, not only the reviews, but also the classification models, feature extraction models, and/or query models were varied in the simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8ae8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the the classification, feature extraction, and query model(s) that were tested\n",
    "train_models = [LogisticClassifier(), NaiveBayesClassifier(), SVMClassifier()] \n",
    "feature_models = [Tfidf(), SBERT()] \n",
    "query_models = [MaxQuery()]\n",
    "\n",
    "# Specify the number of simulations per review-model combination  \n",
    "n_simulations = 200 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d456f158",
   "metadata": {},
   "source": [
    "All the output from the simulations of these variations (conducted on the HPC) can then be retrieved and merged as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bac00ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the review-model combination names\n",
    "sim_list_names = []\n",
    "for review in review_dic:\n",
    "    for train_model in train_models:\n",
    "        for feature_model in feature_models:\n",
    "            for query_model in query_models:\n",
    "                review_id = str(review + \"_\" + train_model.name + \"_\" + feature_model.name + \"_\" + query_model.name)\n",
    "                sim_list_names.append(review_id)\n",
    "                \n",
    "# Retrieve the output from the HPC generated pickle files with each having the rankings of a single simulation\n",
    "multiple_sims = []\n",
    "for i in range(0, len(sim_list_names)):\n",
    "    raw_output = {}\n",
    "    for j in range(1,n_simulations+1):\n",
    "        if Path(path_results_HPC +'sim_{review_id}_{sim}.p'.format(review_id=sim_list_names[i], sim=j)).is_file():\n",
    "            with open(path_results_HPC + 'sim_{review_id}_{sim}.p'.format(review_id=sim_list_names[i], sim=j),'rb') as f:\n",
    "                raw_output.update(pickle.load(f))\n",
    "    if len(raw_output) > 0:\n",
    "        multiple_sims.append((sim_list_names[i], len(review_dic[sim_list_names[i].split('_')[0]]), n_simulations, raw_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67891f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save (back-up) the file with the simulation results \n",
    "# with open(path_results + 'multiple_sims.p','wb') as f:\n",
    "#     pickle.dump(multiple_sims, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d6741",
   "metadata": {},
   "source": [
    "or the output can be directly opened from the already saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a63cd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file with the simulation results\n",
    "with open(path_results + 'multiple_sims.p','rb') as f:\n",
    "    multiple_sims = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5988cb",
   "metadata": {},
   "source": [
    "### 4. Compute performance metrics from the retrieved simulation output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91733d01",
   "metadata": {},
   "source": [
    "The proportions (i.e. proportion of records screened) and sample sizes (i.e. the number of records screened) of interest can be defined. These are then used for evaluation of the ranking of the records and to calculate the performance metrics at each of these proportions/sample sizes screened. These calculations may take a while to run, therefore they were previously saved and can also directly be opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab19fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "sample_sizes = list(map(int,list(np.linspace(0, 99, 100,retstep = True)[0]))) + list(map(int,list(np.linspace(100, 12400, 124,retstep = True)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4937ee",
   "metadata": {},
   "source": [
    "Using these proportions and sizes, the following function can be used to derive the performance metrics of the simulation(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7017cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the compute_metrics function to compute the metrics from the retrieved simulation output\n",
    "#raw_output = compute_metrics.compute_metrics(multiple_sims, proportions, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb94b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save (back-up) a file with the computed output\n",
    "# with open(path_results + 'sims_output.p','wb') as f:\n",
    "#     pickle.dump(raw_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c728ac0",
   "metadata": {},
   "source": [
    "Or directly open the file containing the output (as these especially take a while to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "091b1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file with the computed output\n",
    "with open(path_results + 'sims_output.p','rb') as f: #'sims_output_saved_all_final_2okt.p','rb') as f: #'sims_output_saved_all_final_extra.p','rb') as f:\n",
    "    raw_output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befaa63",
   "metadata": {},
   "source": [
    "### 5. Create raw tables with all performance metrics seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf256f7",
   "metadata": {},
   "source": [
    "Filter the (for now) relevant parts of the output for the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c46199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = {}\n",
    "for i in range(0, len(raw_output)):\n",
    "    evaluation[raw_output[i][0]] = []\n",
    "    evaluation[raw_output[i][0]].append(raw_output[i][3:9])\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9f3c0",
   "metadata": {},
   "source": [
    "Create a raw table with the performance metrics for proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4810fdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Simulation number</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Query model</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>percentage of records screened</th>\n",
       "      <th>recall</th>\n",
       "      <th>Review_full</th>\n",
       "      <th>Models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (logistic - tfidf)</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (logistic - tfidf)</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (logistic - tfidf)</td>\n",
       "      <td>20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (logistic - tfidf)</td>\n",
       "      <td>30%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (logistic - tfidf)</td>\n",
       "      <td>40%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142995</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>200</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (svm - sbert)</td>\n",
       "      <td>60%</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>sbert - svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142996</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>200</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (svm - sbert)</td>\n",
       "      <td>70%</td>\n",
       "      <td>0.982922</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>sbert - svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142997</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>200</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (svm - sbert)</td>\n",
       "      <td>80%</td>\n",
       "      <td>0.992410</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>sbert - svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142998</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>200</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (svm - sbert)</td>\n",
       "      <td>90%</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>sbert - svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142999</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>200</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (svm - sbert)</td>\n",
       "      <td>100%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>sbert - svm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review  Simulation number Train model Feature model Query model  \\\n",
       "0        Int1                  1    logistic         tfidf         max   \n",
       "1        Int1                  1    logistic         tfidf         max   \n",
       "2        Int1                  1    logistic         tfidf         max   \n",
       "3        Int1                  1    logistic         tfidf         max   \n",
       "4        Int1                  1    logistic         tfidf         max   \n",
       "...       ...                ...         ...           ...         ...   \n",
       "142995  Prog6                200         svm         sbert         max   \n",
       "142996  Prog6                200         svm         sbert         max   \n",
       "142997  Prog6                200         svm         sbert         max   \n",
       "142998  Prog6                200         svm         sbert         max   \n",
       "142999  Prog6                200         svm         sbert         max   \n",
       "\n",
       "                               Simulation percentage of records screened  \\\n",
       "0       Intervention 1 (logistic - tfidf)                             0%   \n",
       "1       Intervention 1 (logistic - tfidf)                            10%   \n",
       "2       Intervention 1 (logistic - tfidf)                            20%   \n",
       "3       Intervention 1 (logistic - tfidf)                            30%   \n",
       "4       Intervention 1 (logistic - tfidf)                            40%   \n",
       "...                                   ...                            ...   \n",
       "142995          Prognosis 6 (svm - sbert)                            60%   \n",
       "142996          Prognosis 6 (svm - sbert)                            70%   \n",
       "142997          Prognosis 6 (svm - sbert)                            80%   \n",
       "142998          Prognosis 6 (svm - sbert)                            90%   \n",
       "142999          Prognosis 6 (svm - sbert)                           100%   \n",
       "\n",
       "          recall     Review_full            Models  \n",
       "0       0.000000  Intervention 1  tfidf - logistic  \n",
       "1       0.977273  Intervention 1  tfidf - logistic  \n",
       "2       1.000000  Intervention 1  tfidf - logistic  \n",
       "3       1.000000  Intervention 1  tfidf - logistic  \n",
       "4       1.000000  Intervention 1  tfidf - logistic  \n",
       "...          ...             ...               ...  \n",
       "142995  0.964896     Prognosis 6       sbert - svm  \n",
       "142996  0.982922     Prognosis 6       sbert - svm  \n",
       "142997  0.992410     Prognosis 6       sbert - svm  \n",
       "142998  0.996205     Prognosis 6       sbert - svm  \n",
       "142999  1.000000     Prognosis 6       sbert - svm  \n",
       "\n",
       "[143000 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the generate_recall_table_prop function to generate a table with all recall values for all proportions\n",
    "df_prop = generate_recall_table_prop.generate_recall_table_prop(evaluation, proportions, n_simulations)\n",
    "df_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50899057",
   "metadata": {},
   "source": [
    "Calculate the maximum recall values that could be obtained at each of the proportions screened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "054470e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Maximum recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Review  Maximum recall\n",
       "0     Int1             0.0\n",
       "1     Int1             1.0\n",
       "2     Int1             1.0\n",
       "3     Int1             1.0\n",
       "4     Int1             1.0\n",
       "..     ...             ...\n",
       "138  Prog6             1.0\n",
       "139  Prog6             1.0\n",
       "140  Prog6             1.0\n",
       "141  Prog6             1.0\n",
       "142  Prog6             1.0\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dictionary\n",
    "review_dic_ord = collections.OrderedDict(sorted(review_dic.items()))\n",
    "# Use the max_recall_prop function to calculate the maximum achievable recall for each review\n",
    "df_max_recalls = max_recall_prop.max_recall_prop(review_dic_ord, proportions)\n",
    "df_max_recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be693a6",
   "metadata": {},
   "source": [
    "Create a raw table with the work-saved-over sampling, normalized work-saved-over sampling, workload reduction in number of records, and workload reduction in hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d92b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Query model</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>WSS@95%</th>\n",
       "      <th>n-WSS@95%</th>\n",
       "      <th>Workload reduction (n)</th>\n",
       "      <th>Workload reduction (hours)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870961</td>\n",
       "      <td>0.925022</td>\n",
       "      <td>8436</td>\n",
       "      <td>70.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>2</td>\n",
       "      <td>0.864956</td>\n",
       "      <td>0.918975</td>\n",
       "      <td>8381</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>3</td>\n",
       "      <td>0.880022</td>\n",
       "      <td>0.934147</td>\n",
       "      <td>8519</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>4</td>\n",
       "      <td>0.864956</td>\n",
       "      <td>0.918975</td>\n",
       "      <td>8381</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>5</td>\n",
       "      <td>0.866048</td>\n",
       "      <td>0.920075</td>\n",
       "      <td>8391</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>196</td>\n",
       "      <td>0.420118</td>\n",
       "      <td>0.618120</td>\n",
       "      <td>1880</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>197</td>\n",
       "      <td>0.399112</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>1796</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>198</td>\n",
       "      <td>0.411115</td>\n",
       "      <td>0.605812</td>\n",
       "      <td>1844</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>199</td>\n",
       "      <td>0.402113</td>\n",
       "      <td>0.593504</td>\n",
       "      <td>1808</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12999</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>200</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>0.616752</td>\n",
       "      <td>1876</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Review Train model Feature model Query model  Simulation   WSS@95%  \\\n",
       "0       Int1    logistic         tfidf         max           1  0.870961   \n",
       "1       Int1    logistic         tfidf         max           2  0.864956   \n",
       "2       Int1    logistic         tfidf         max           3  0.880022   \n",
       "3       Int1    logistic         tfidf         max           4  0.864956   \n",
       "4       Int1    logistic         tfidf         max           5  0.866048   \n",
       "...      ...         ...           ...         ...         ...       ...   \n",
       "12995  Prog6         svm         sbert         max         196  0.420118   \n",
       "12996  Prog6         svm         sbert         max         197  0.399112   \n",
       "12997  Prog6         svm         sbert         max         198  0.411115   \n",
       "12998  Prog6         svm         sbert         max         199  0.402113   \n",
       "12999  Prog6         svm         sbert         max         200  0.419117   \n",
       "\n",
       "       n-WSS@95%  Workload reduction (n)  Workload reduction (hours)  \n",
       "0       0.925022                    8436                        70.3  \n",
       "1       0.918975                    8381                        69.8  \n",
       "2       0.934147                    8519                        71.0  \n",
       "3       0.918975                    8381                        69.8  \n",
       "4       0.920075                    8391                        69.9  \n",
       "...          ...                     ...                         ...  \n",
       "12995   0.618120                    1880                        15.7  \n",
       "12996   0.589744                    1796                        15.0  \n",
       "12997   0.605812                    1844                        15.4  \n",
       "12998   0.593504                    1808                        15.1  \n",
       "12999   0.616752                    1876                        15.6  \n",
       "\n",
       "[13000 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the generate_wss_table function to create a table with the workload metrics\n",
    "df_wss = generate_wss_table.generate_wss_table(evaluation, n_simulations)\n",
    "#df_wss.to_excel('results/table_wss.xlsx')\n",
    "df_wss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed65001",
   "metadata": {},
   "source": [
    "Create a raw table with the precision metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01499b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Query model</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Precision@95%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>3</td>\n",
       "      <td>0.062402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>4</td>\n",
       "      <td>0.053915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>5</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>196</td>\n",
       "      <td>0.472393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>197</td>\n",
       "      <td>0.458012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>198</td>\n",
       "      <td>0.465429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>199</td>\n",
       "      <td>0.460064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12999</th>\n",
       "      <td>Prog6</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>max</td>\n",
       "      <td>200</td>\n",
       "      <td>0.471974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Review Train model Feature model Query model  Simulation  Precision@95%\n",
       "0       Int1    logistic         tfidf         max           1       0.058011\n",
       "1       Int1    logistic         tfidf         max           2       0.053915\n",
       "2       Int1    logistic         tfidf         max           3       0.062402\n",
       "3       Int1    logistic         tfidf         max           4       0.053915\n",
       "4       Int1    logistic         tfidf         max           5       0.054616\n",
       "...      ...         ...           ...         ...         ...            ...\n",
       "12995  Prog6         svm         sbert         max         196       0.472393\n",
       "12996  Prog6         svm         sbert         max         197       0.458012\n",
       "12997  Prog6         svm         sbert         max         198       0.465429\n",
       "12998  Prog6         svm         sbert         max         199       0.460064\n",
       "12999  Prog6         svm         sbert         max         200       0.471974\n",
       "\n",
       "[13000 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prec = pd.DataFrame()\n",
    "length = n_simulations\n",
    "for key, value in evaluation.items():\n",
    "    names = key.split('_')\n",
    "    review = [names[0]] * length\n",
    "    train_model = [names[1]] * length\n",
    "    feature_model = [names[2]] * length\n",
    "    query_model = [names[3]] * length\n",
    "    simulations = range(1, n_simulations+1)\n",
    "    precision = value[0][4]['Precision'] ###\n",
    "    df_sim = pd.DataFrame(list(zip(review,train_model,feature_model,query_model,simulations, precision)),\n",
    "                           columns = ['Review', 'Train model', 'Feature model', 'Query model', 'Simulation', 'Precision@95%'])\n",
    "    df_prec = pd.concat([df_prec, df_sim])\n",
    "\n",
    "    df_prec = df_prec.reset_index(drop = True)\n",
    "    \n",
    "df_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ef690",
   "metadata": {},
   "source": [
    "### 6. Process raw tables into pooled tables (for results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a104773f",
   "metadata": {},
   "source": [
    "The generate_results_table function creates the table containing the WSS and precision values as presented in te results (df_wss_prec) and the table used for create figures (df_wss_prec_all_values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86be4f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Mean_WSS95</th>\n",
       "      <th>ci95_hi_WSS95</th>\n",
       "      <th>ci95_lo_WSS95</th>\n",
       "      <th>Mean_nWSS95</th>\n",
       "      <th>ci95_hi_nWSS95</th>\n",
       "      <th>ci95_lo_nWSS95</th>\n",
       "      <th>Mean_prec95</th>\n",
       "      <th>ci95_hi_prec95</th>\n",
       "      <th>ci95_lo_prec95</th>\n",
       "      <th>Mean_workred_n</th>\n",
       "      <th>ci95_hi_workred_n</th>\n",
       "      <th>ci95_lo_workred_n</th>\n",
       "      <th>Mean_workred_hr</th>\n",
       "      <th>ci95_hi_workred_hr</th>\n",
       "      <th>ci95_lo_workred_hr</th>\n",
       "      <th>Models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sbert</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.053</td>\n",
       "      <td>8,273</td>\n",
       "      <td>8319</td>\n",
       "      <td>8227</td>\n",
       "      <td>68.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>68.6</td>\n",
       "      <td>sbert - logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.054</td>\n",
       "      <td>8,386</td>\n",
       "      <td>8398</td>\n",
       "      <td>8374</td>\n",
       "      <td>69.9</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>tfidf - logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.053</td>\n",
       "      <td>8,366</td>\n",
       "      <td>8374</td>\n",
       "      <td>8359</td>\n",
       "      <td>69.7</td>\n",
       "      <td>69.8</td>\n",
       "      <td>69.7</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.048</td>\n",
       "      <td>8,193</td>\n",
       "      <td>8243</td>\n",
       "      <td>8144</td>\n",
       "      <td>68.3</td>\n",
       "      <td>68.7</td>\n",
       "      <td>67.9</td>\n",
       "      <td>sbert - svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>svm</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.042</td>\n",
       "      <td>8,196</td>\n",
       "      <td>8215</td>\n",
       "      <td>8178</td>\n",
       "      <td>68.3</td>\n",
       "      <td>68.5</td>\n",
       "      <td>68.1</td>\n",
       "      <td>tfidf - svm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Review Train model Feature model Mean_WSS95 ci95_hi_WSS95 ci95_lo_WSS95  \\\n",
       "0   Int1    logistic         sbert      0.853         0.858         0.848   \n",
       "1   Int1    logistic         tfidf      0.866         0.867         0.864   \n",
       "2   Int1          nb         tfidf      0.863         0.864         0.863   \n",
       "3   Int1         svm         sbert      0.844         0.850         0.839   \n",
       "4   Int1         svm         tfidf      0.845         0.847         0.843   \n",
       "\n",
       "  Mean_nWSS95 ci95_hi_nWSS95 ci95_lo_nWSS95 Mean_prec95 ci95_hi_prec95  \\\n",
       "0       0.907          0.912          0.902       0.058          0.062   \n",
       "1       0.920          0.921          0.918       0.054          0.055   \n",
       "2       0.917          0.918          0.917       0.054          0.054   \n",
       "3       0.898          0.904          0.893       0.051          0.054   \n",
       "4       0.899          0.901          0.897       0.043          0.044   \n",
       "\n",
       "  ci95_lo_prec95 Mean_workred_n ci95_hi_workred_n ci95_lo_workred_n  \\\n",
       "0          0.053          8,273              8319              8227   \n",
       "1          0.054          8,386              8398              8374   \n",
       "2          0.053          8,366              8374              8359   \n",
       "3          0.048          8,193              8243              8144   \n",
       "4          0.042          8,196              8215              8178   \n",
       "\n",
       "  Mean_workred_hr ci95_hi_workred_hr ci95_lo_workred_hr            Models  \n",
       "0            68.9               69.3               68.6  sbert - logistic  \n",
       "1            69.9               70.0               69.8  tfidf - logistic  \n",
       "2            69.7               69.8               69.7        tfidf - nb  \n",
       "3            68.3               68.7               67.9       sbert - svm  \n",
       "4            68.3               68.5               68.1       tfidf - svm  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wss_prec_all_values, df_wss_prec = generate_results_table.generate_results_table(df_wss, df_prec)\n",
    "#df_wss_prec.to_excel('results/table_wss_precision.xlsx')\n",
    "\n",
    "df_wss_prec_all_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "349223ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>WSS@95%recall (CI)</th>\n",
       "      <th>n-WSS@95%recall (CI)</th>\n",
       "      <th>Precision@95%recall (CI)</th>\n",
       "      <th>Workload reduction in record numbers (CI)</th>\n",
       "      <th>Workload reduction in hours (CI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>sbert</td>\n",
       "      <td>0.853 (0.848-0.858)</td>\n",
       "      <td>0.907 (0.902-0.912)</td>\n",
       "      <td>0.058 (0.053-0.062)</td>\n",
       "      <td>8,273 (8227-8319)</td>\n",
       "      <td>68.9 (68.6-69.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>logistic</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.866 (0.864-0.867)</td>\n",
       "      <td>0.920 (0.918-0.921)</td>\n",
       "      <td>0.054 (0.054-0.055)</td>\n",
       "      <td>8,386 (8374-8398)</td>\n",
       "      <td>69.9 (69.8-70.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.863 (0.863-0.864)</td>\n",
       "      <td>0.917 (0.917-0.918)</td>\n",
       "      <td>0.054 (0.053-0.054)</td>\n",
       "      <td>8,366 (8359-8374)</td>\n",
       "      <td>69.7 (69.7-69.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>svm</td>\n",
       "      <td>sbert</td>\n",
       "      <td>0.844 (0.839-0.850)</td>\n",
       "      <td>0.898 (0.893-0.904)</td>\n",
       "      <td>0.051 (0.048-0.054)</td>\n",
       "      <td>8,193 (8144-8243)</td>\n",
       "      <td>68.3 (67.9-68.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>svm</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.845 (0.843-0.847)</td>\n",
       "      <td>0.899 (0.897-0.901)</td>\n",
       "      <td>0.043 (0.042-0.044)</td>\n",
       "      <td>8,196 (8178-8215)</td>\n",
       "      <td>68.3 (68.1-68.5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Review Train model Feature model   WSS@95%recall (CI) n-WSS@95%recall (CI)  \\\n",
       "0   Int1    logistic         sbert  0.853 (0.848-0.858)  0.907 (0.902-0.912)   \n",
       "1   Int1    logistic         tfidf  0.866 (0.864-0.867)  0.920 (0.918-0.921)   \n",
       "2   Int1          nb         tfidf  0.863 (0.863-0.864)  0.917 (0.917-0.918)   \n",
       "3   Int1         svm         sbert  0.844 (0.839-0.850)  0.898 (0.893-0.904)   \n",
       "4   Int1         svm         tfidf  0.845 (0.843-0.847)  0.899 (0.897-0.901)   \n",
       "\n",
       "  Precision@95%recall (CI) Workload reduction in record numbers (CI)  \\\n",
       "0      0.058 (0.053-0.062)                         8,273 (8227-8319)   \n",
       "1      0.054 (0.054-0.055)                         8,386 (8374-8398)   \n",
       "2      0.054 (0.053-0.054)                         8,366 (8359-8374)   \n",
       "3      0.051 (0.048-0.054)                         8,193 (8144-8243)   \n",
       "4      0.043 (0.042-0.044)                         8,196 (8178-8215)   \n",
       "\n",
       "  Workload reduction in hours (CI)  \n",
       "0                 68.9 (68.6-69.3)  \n",
       "1                 69.9 (69.8-70.0)  \n",
       "2                 69.7 (69.7-69.8)  \n",
       "3                 68.3 (67.9-68.7)  \n",
       "4                 68.3 (68.1-68.5)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wss_prec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7464bd",
   "metadata": {},
   "source": [
    "### 7. Create histograms for WSS and precision (for results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bec866",
   "metadata": {},
   "source": [
    "Create histograms for (n-)WSS and precision for intervention and prognosis reviews seperately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaa15956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histograms(dataset, x, variables, y_labels, review_types, y_lims, hue = 'Models'):\n",
    "    \n",
    "    dataset['Models'] = dataset['Models'].astype(pd.CategoricalDtype(categories=['tfidf - nb',\n",
    "                                                                                 'tfidf - svm',\n",
    "                                                                                 'tfidf - logistic',\n",
    "                                                                                 'sbert - svm',\n",
    "                                                                                 'sbert - logistic']))\n",
    "\n",
    "    # Change dtype to numeric\n",
    "    for variable in variables:\n",
    "        dataset[variable] = pd.to_numeric(dataset[variable])\n",
    "        \n",
    "    # Create a histogram for each variable and review type\n",
    "    for i in range(0, len(variables)):\n",
    "        for j in review_types:\n",
    "            \n",
    "            sns.barplot(x=x, y=variables[i], hue=hue, \n",
    "                        data=dataset[dataset['Review'].str.startswith(j)]).set(ylabel=y_labels[i],ylim=(0,y_lims[i]))\n",
    "            plt.legend(fontsize='10', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "852dd987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variables to plot\n",
    "variables_to_plot = ['Mean_WSS95', 'Mean_nWSS95', 'Mean_prec95']\n",
    "variable_names = ['WSS@95', 'n-WSS@95', 'Precision@95%']\n",
    "y_lims = [1,1,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dab64bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "review_types = ['Prog']\n",
    "generate_histograms(dataset=df_wss_prec_all_values, \n",
    "                    x='Review',\n",
    "                    variables=variables_to_plot, \n",
    "                    y_labels=variable_names, \n",
    "                    review_types=review_types,\n",
    "                    y_lims=y_lims);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2347f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "review_types = ['Int']\n",
    "generate_histograms(dataset=df_wss_prec_all_values[~df_wss_prec_all_values['Review'].str.contains('Int7', na=False)], \n",
    "                    x='Review',\n",
    "                    variables=variables_to_plot, \n",
    "                    y_labels=variable_names, \n",
    "                    review_types=review_types,\n",
    "                    y_lims=y_lims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee434fda",
   "metadata": {},
   "source": [
    "### 8. Create boxplots/lineplots of increasing recall during screening (for results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95e5f1",
   "metadata": {},
   "source": [
    "Create boxplots for the simulations of the default models (or any other subset of data/modeling methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02b6bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally choose subset(s) to plot\n",
    "subset_models = ['nb - tfidf']\n",
    "subset_reviews = ['Prog', 'Int']\n",
    "\n",
    "def generate_boxplots(df_prop, df_max_recalls, subset_models = None, subset_reviews = None):\n",
    "    \n",
    "    # Select the subset from the dataframe containing all recall values for each proportion screened\n",
    "    df_boxplots = df_prop.copy()\n",
    "    \n",
    "    if subset_models != None:\n",
    "        models = '|'.join(subset_models)\n",
    "        df_boxplots = df_boxplots[df_boxplots['Simulation'].str.contains(models, regex=True)]\n",
    "    if subset_reviews != None:\n",
    "        reviews = '|'.join(subset_reviews)\n",
    "        df_boxplots = df_boxplots[df_boxplots['Review'].str.contains(reviews, regex=True)]\n",
    "\n",
    "    # Create a figure with boxplots for each review-model combination seperately\n",
    "    sns.set(style = 'ticks', font_scale = 1.5)\n",
    "    p1 = sns.catplot(data = df_boxplots, x = 'percentage of records screened', y = 'recall',\n",
    "                     col = 'Simulation', kind = 'box', col_wrap = 2, color = 'white', aspect = 1.3)\n",
    "\n",
    "    axes = p1.fig.axes\n",
    "    x_axis = df_boxplots['percentage of records screened'][0:11]\n",
    "\n",
    "    for i in range(0, len(df_boxplots['Simulation'].unique())):\n",
    "        review = df_boxplots.loc[df_boxplots['Simulation'] == df_boxplots['Simulation'].unique()[i], 'Review'].values[0]\n",
    "        max_recalls_per_prop = df_max_recalls.loc[df_max_recalls['Review'] == review]['Maximum recall']    \n",
    "        axes[i].plot(x_axis, max_recalls_per_prop+0.005, 'k-', linewidth = 1, color = 'black', linestyle = '--', label = \"maximal recall\")   \n",
    "        axes[i].legend(loc=\"lower right\")\n",
    "    p1.set_titles(col_template = \"{col_name}\", size = 16, weight = 'bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46e8c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "generate_boxplots(df_prop, df_max_recalls, subset_models, subset_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84377abd",
   "metadata": {},
   "source": [
    "Create lineplots for all simulations (or any other subset of data/modeling methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69d62cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally choose a subset to plot\n",
    "subset_reviews = ['Prog']\n",
    "\n",
    "def generate_lineplots(df_prop, df_max_recalls, subset_reviews = None):\n",
    "    \n",
    "    # Select the subset from the dataframe containing all recall values for each proportion screened\n",
    "    df_lineplots = df_prop.copy()\n",
    "    \n",
    "    df_lineplots['Models'] = df_lineplots['Models'].astype(pd.CategoricalDtype(categories=['tfidf - nb',\n",
    "                                                                  'tfidf - svm',\n",
    "                                                                  'tfidf - logistic',\n",
    "                                                                  'sbert - svm',\n",
    "                                                                  'sbert - logistic']))\n",
    "    \n",
    "    if subset_reviews != None:\n",
    "        reviews = '|'.join(subset_reviews)\n",
    "        df_lineplots = df_lineplots[df_lineplots['Review'].str.contains(reviews, regex=True)]\n",
    "\n",
    "    # Create a figure with lineplots for each review-model combination seperately\n",
    "    p2 = sns.catplot(data = df_lineplots, kind = 'point', \n",
    "                     x = 'percentage of records screened', y = 'recall', \n",
    "                     col = 'Review_full', \n",
    "                     hue = 'Models', \n",
    "                     errorbar = 'ci',\n",
    "                     col_wrap = 2, aspect = 1.4, legend = False\n",
    "                     )\n",
    "\n",
    "    axes = p2.fig.axes\n",
    "\n",
    "    for i in range(0, len(df_lineplots['Review'].unique())):\n",
    "        max_recalls_per_prop = df_max_recalls.loc[df_max_recalls['Review'] == df_lineplots['Review'].unique()[i]]['Maximum recall']    \n",
    "        manual_screening = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "        x_axis = df_lineplots['percentage of records screened'][0:len(max_recalls_per_prop)]\n",
    "        axes[i].plot(x_axis, max_recalls_per_prop + 0.005, 'k-', linewidth = 1, color = 'grey', linestyle = '--', label = \"maximum recall\") \n",
    "        axes[i].plot(x_axis, manual_screening, 'k-', linewidth = 1, color = 'grey', linestyle = '-', label = \"manual screening\") \n",
    "        axes[i].legend(loc=\"lower right\", fontsize = 12.5)\n",
    "    \n",
    "    if subset_reviews[0] == 'Int7':\n",
    "        p2.set_titles('Intervention A1', size = 16, weight = 'bold')\n",
    "    else:\n",
    "        p2.set_titles(col_template = \"{col_name}\", size = 16, weight = 'bold')\n",
    "    p2.set_xlabels('Percentage of records screened', size = 16)\n",
    "    p2.set_ylabels('Recall', size = 16)\n",
    "    p2.set(ylim = (0, 1.01))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "613d549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "generate_lineplots(df_prop, df_max_recalls, subset_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "680936a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "subset_reviews = ['Int1', 'Int2', 'Int3', 'Int4', 'Int5', 'Int6']\n",
    "generate_lineplots(df_prop, df_max_recalls, subset_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d03e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "subset_reviews = ['Int7']\n",
    "generate_lineplots(df_prop, df_max_recalls, subset_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3d8fa",
   "metadata": {},
   "source": [
    "## Part III: Simulations with adapted review datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812df3c",
   "metadata": {},
   "source": [
    "### 9. Variations in number of (relevant) records "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db099cfa",
   "metadata": {},
   "source": [
    "Create dataframes of manually adapted numbers of (relevant) records that were also used to simulate the semi-automated screening process on the High Performance Computer (HPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feb61852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a dictionary with subsets of a dataset consisting of varying numbers of records and inclusions:\n",
    "\n",
    "def df_var_dict(review_name, df, sizes, incl_prop): \n",
    "    \n",
    "    '''\n",
    "    df (pandas.DataFrame):    a dataframe of a review with at least containing the columns 'abstract', 'title', and 'label_included'\n",
    "    sizes (list):             a list of integers of dataframe sizes to vary  \n",
    "    incl_prop (list):         a list of integers of inclusion proportions to vary \n",
    "    '''\n",
    "    \n",
    "    # First a list of possible size/inclusion combinations is created:\n",
    "    unique_combinations = []\n",
    "    for i in range(0, len(sizes)):\n",
    "        unique_combinations.append([sizes[i],incl_prop[i]])\n",
    "\n",
    "    # Then a dictionary is created with for each combination a sample of the dataset. If the sample cannot be retrieved,\n",
    "    # i.e. the dataset size is too small or the inclusion proportion is not available, the respective item in the dictionary remains empty.\n",
    "    df_dict = {}\n",
    "    \n",
    "    # For each combination of size/inclusion proportion:\n",
    "    for i in range(len(unique_combinations)):\n",
    "        # Check if the dataframe includes enough records to sample the respective size\n",
    "        if len(df) >= unique_combinations[i][0]:\n",
    "            \n",
    "            \n",
    "            # Check if the inclusion proportion is possible for the respective size\n",
    "            if df.loc[df['label_included'] == 1].shape[0] >= int(unique_combinations[i][0] * unique_combinations[i][1]) and df.loc[df['label_included'] == 0].shape[0] >= int(unique_combinations[i][0] - (unique_combinations[i][0] * unique_combinations[i][1])):\n",
    "                # If so:\n",
    "                # Sample random inclusions\n",
    "                incl = df.loc[df['label_included'] == 1].sample(n = int(unique_combinations[i][0] * unique_combinations[i][1]), replace = False, random_state = 1)\n",
    "                # Sample random exclusions\n",
    "                excl = df.loc[df['label_included'] == 0].sample(n = int(unique_combinations[i][0] - (unique_combinations[i][0] * unique_combinations[i][1])), replace = False, random_state = 1)\n",
    "                # Create a dataframe of the inclusions and exclusions\n",
    "                df_new = pd.concat([incl, excl]).sort_values('authors').reset_index()\n",
    "                name = review_name + \"_\" + str(len(df_new)) + \"_\" + str(unique_combinations[i][1])\n",
    "            # If the size/inclusion proportion is not possible, leave the dataframe empty\n",
    "            else:\n",
    "                name = review_name + \"_\" + str(len(df_new)) + \"_\" + str(unique_combinations[i][1])\n",
    "                df_new = [] \n",
    "        else:\n",
    "            df_new = []\n",
    "        \n",
    "        if len(df_new) > 0:\n",
    "            if df_new['label_included'].sum() <= 10:\n",
    "                df_new = []\n",
    "        \n",
    "        # Store the dataframe in the dictionary of all retrieved dataframes\n",
    "        if len(df_new) > 0:\n",
    "            df_dict[name] = df_new\n",
    "  \n",
    "    return(df_dict)\n",
    "\n",
    "# Apply the function:\n",
    "sizes = [500, 1000, 2000]\n",
    "incl_prop = [0.1, 0.05, 0.025]\n",
    "ss_dict = df_var_dict(review_name = 'Int1', df = dfs_int['Int1'], sizes = sizes, incl_prop = incl_prop)                 \n",
    "ss_dict.update(df_var_dict(review_name = 'Int2', df = dfs_int['Int2'], sizes = sizes, incl_prop = incl_prop))\n",
    "ss_dict.update(df_var_dict(review_name = 'Int4', df = dfs_int['Int4'], sizes = sizes, incl_prop = incl_prop))\n",
    "ss_dict.update(df_var_dict(review_name = 'Int6', df = dfs_int['Int6'], sizes = sizes, incl_prop = incl_prop))\n",
    "ss_dict.update(df_var_dict(review_name = 'Prog3', df = dfs_prog['Prog3'], sizes = sizes, incl_prop = incl_prop))\n",
    "ss_dict.update(df_var_dict(review_name = 'Prog4', df = dfs_prog['Prog4'], sizes = sizes, incl_prop = incl_prop))\n",
    "ss_dict.update(df_var_dict(review_name = 'Prog5', df = dfs_prog['Prog5'], sizes = sizes, incl_prop = incl_prop))\n",
    "ss_dict.update(df_var_dict(review_name = 'Prog6', df = dfs_prog['Prog6'], sizes = sizes, incl_prop = incl_prop))\n",
    "\n",
    "# Save the keys\n",
    "ss_sims = list(ss_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa399e",
   "metadata": {},
   "source": [
    "### 10. Retrieve and merge the output from all simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a3c556",
   "metadata": {},
   "source": [
    "To assess the performance of the semi-automated screening tool, the classification models, feature extraction models, and/or query models were kept constant while the reviews were manually adapted to consist of equal number of (relevant) records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2be9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results_HPC = 'output/simulations_adapted_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7be833d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the the classification, feature extraction, and query model(s) that were tested\n",
    "train_models = [NaiveBayesClassifier()]\n",
    "feature_models = [Tfidf()] \n",
    "query_models = [MaxQuery()]\n",
    "\n",
    "# Specify the number of simulations per review-model combination  \n",
    "n_simulations = 200 \n",
    "\n",
    "# Specify the number of sampling seeds of manually adapted datasets\n",
    "seeds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f1f8c",
   "metadata": {},
   "source": [
    "All the output from the simulations of these variations (conducted on the HPC) can then be retrieved and merged as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02684671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the review-model combination names\n",
    "sim_list_names_ss = []\n",
    "for review in ss_sims:\n",
    "    for train_model in train_models:\n",
    "        for feature_model in feature_models:\n",
    "            for query_model in query_models:\n",
    "                review_id = str(review + \"_\" + train_model.name + \"_\" + feature_model.name + \"_\" + query_model.name)\n",
    "                sim_list_names_ss.append(review_id)\n",
    "\n",
    "# Derive the results from the HPC retrieved pickle files with each having the rankings of a single simulation\n",
    "multiple_sims_sizes = []\n",
    "n_simulations = 200 # number of simulations per review-model combination\n",
    "for i in range(0, len(sim_list_names_ss)):\n",
    "    for k in range(1, seeds+1):\n",
    "        raw_output_ss = {}\n",
    "        for j in range(1,n_simulations+1):\n",
    "            if Path(path_results_HPC +'sim_{review_id}_{sim}_{seed}.p'.format(review_id=sim_list_names_ss[i], sim=j, seed = k)).is_file():\n",
    "                with open(path_results_HPC + 'sim_{review_id}_{sim}_{seed}.p'.format(review_id=sim_list_names_ss[i], sim=j, seed = k),'rb') as f:\n",
    "                    raw_output_ss.update(pickle.load(f))\n",
    "        if len(raw_output_ss) > 0:\n",
    "            review_id = str(sim_list_names_ss[i] + '_' + str(k))\n",
    "            multiple_sims_sizes.append((review_id, len(ss_dict['_'.join(sim_list_names_ss[0].split('_')[0:3])]), n_simulations, raw_output_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54fd2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save (back-up) the file with the simulation results\n",
    "# with open(path_results + 'multiple_sims_sizes.p','wb') as f:\n",
    "#     pickle.dump(multiple_sims_sizes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c4e05",
   "metadata": {},
   "source": [
    "or the output can be directly opened from the already saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f06d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file with the simulation results\n",
    "with open(path_results + 'multiple_sims_sizes.p','rb') as f:\n",
    "    multiple_sims_sizes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84a9ea",
   "metadata": {},
   "source": [
    "### 11. Compute performance metrics from the retrieved simulation output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af20870",
   "metadata": {},
   "source": [
    "The proportions (i.e. proportion of records screened) and sample sizes (i.e. the number of records screened) of interest can be defined. These are then used for evaluation of the ranking of the records and to calculate the performance metrics at each of these proportions/sample sizes screened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c66a9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "sample_sizes = list(map(int,list(np.linspace(0, 99, 100,retstep = True)[0]))) + list(map(int,list(np.linspace(100, 12400, 124,retstep = True)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a8a77",
   "metadata": {},
   "source": [
    "Using these proportions and sizes, the following function can be used to derive the performance metrics of the simulation(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47ce7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the compute_metrics function to compute the metrics from the retrieved simulation output\n",
    "#raw_output_sizes = compute_metrics.compute_metrics(multiple_sims_sizes, proportions, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec35a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save (back-up) a file with the computed output\n",
    "# with open(path_results + 'sims_output_sizes.p','wb') as f:\n",
    "#     pickle.dump(raw_output_sizes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d135a",
   "metadata": {},
   "source": [
    "Or directly open the file containing the output (as these especially take a while to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92a6f676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the files with the computed output\n",
    "with open(path_results + 'sims_output_sizes.p','rb') as f:\n",
    "    raw_output_sizes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e846f5c",
   "metadata": {},
   "source": [
    "### 12. Create raw tables with all performance metrics seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed822052",
   "metadata": {},
   "source": [
    "Filter the (for now) relevant parts of the output for the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56f9fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_sizes = {}\n",
    "for i in range(0, len(raw_output_sizes)):\n",
    "    evaluation_sizes[raw_output_sizes[i][0]] = []\n",
    "    evaluation_sizes[raw_output_sizes[i][0]].append(raw_output_sizes[i][3:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a201be3",
   "metadata": {},
   "source": [
    "Create a raw table with the performance metrics for proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "702fe2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Total records</th>\n",
       "      <th>Relevant records</th>\n",
       "      <th>Simulation number</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Query model</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>percentage of records screened</th>\n",
       "      <th>recall</th>\n",
       "      <th>Review_full</th>\n",
       "      <th>Models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (500 - 0.1)</td>\n",
       "      <td>0%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (500 - 0.1)</td>\n",
       "      <td>10%</td>\n",
       "      <td>0.900</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (500 - 0.1)</td>\n",
       "      <td>20%</td>\n",
       "      <td>0.975</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (500 - 0.1)</td>\n",
       "      <td>30%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Intervention 1 (500 - 0.1)</td>\n",
       "      <td>40%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Intervention 1</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263995</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>200</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (2000 - 0.025)</td>\n",
       "      <td>60%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263996</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>200</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (2000 - 0.025)</td>\n",
       "      <td>70%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263997</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>200</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (2000 - 0.025)</td>\n",
       "      <td>80%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263998</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>200</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (2000 - 0.025)</td>\n",
       "      <td>90%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263999</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>200</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>Prognosis 6 (2000 - 0.025)</td>\n",
       "      <td>100%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Prognosis 6</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Review Seed Total records Relevant records  \\\n",
       "0           Int1_500_0.1    1           500              0.1   \n",
       "1           Int1_500_0.1    1           500              0.1   \n",
       "2           Int1_500_0.1    1           500              0.1   \n",
       "3           Int1_500_0.1    1           500              0.1   \n",
       "4           Int1_500_0.1    1           500              0.1   \n",
       "...                  ...  ...           ...              ...   \n",
       "263995  Prog6_2000_0.025    5          2000            0.025   \n",
       "263996  Prog6_2000_0.025    5          2000            0.025   \n",
       "263997  Prog6_2000_0.025    5          2000            0.025   \n",
       "263998  Prog6_2000_0.025    5          2000            0.025   \n",
       "263999  Prog6_2000_0.025    5          2000            0.025   \n",
       "\n",
       "        Simulation number Train model Feature model Query model  \\\n",
       "0                       1          nb         tfidf         max   \n",
       "1                       1          nb         tfidf         max   \n",
       "2                       1          nb         tfidf         max   \n",
       "3                       1          nb         tfidf         max   \n",
       "4                       1          nb         tfidf         max   \n",
       "...                   ...         ...           ...         ...   \n",
       "263995                200          nb         tfidf         max   \n",
       "263996                200          nb         tfidf         max   \n",
       "263997                200          nb         tfidf         max   \n",
       "263998                200          nb         tfidf         max   \n",
       "263999                200          nb         tfidf         max   \n",
       "\n",
       "                        Simulation percentage of records screened  recall  \\\n",
       "0       Intervention 1 (500 - 0.1)                             0%   0.000   \n",
       "1       Intervention 1 (500 - 0.1)                            10%   0.900   \n",
       "2       Intervention 1 (500 - 0.1)                            20%   0.975   \n",
       "3       Intervention 1 (500 - 0.1)                            30%   1.000   \n",
       "4       Intervention 1 (500 - 0.1)                            40%   1.000   \n",
       "...                            ...                            ...     ...   \n",
       "263995  Prognosis 6 (2000 - 0.025)                            60%   1.000   \n",
       "263996  Prognosis 6 (2000 - 0.025)                            70%   1.000   \n",
       "263997  Prognosis 6 (2000 - 0.025)                            80%   1.000   \n",
       "263998  Prognosis 6 (2000 - 0.025)                            90%   1.000   \n",
       "263999  Prognosis 6 (2000 - 0.025)                           100%   1.000   \n",
       "\n",
       "           Review_full      Models  \n",
       "0       Intervention 1  tfidf - nb  \n",
       "1       Intervention 1  tfidf - nb  \n",
       "2       Intervention 1  tfidf - nb  \n",
       "3       Intervention 1  tfidf - nb  \n",
       "4       Intervention 1  tfidf - nb  \n",
       "...                ...         ...  \n",
       "263995     Prognosis 6  tfidf - nb  \n",
       "263996     Prognosis 6  tfidf - nb  \n",
       "263997     Prognosis 6  tfidf - nb  \n",
       "263998     Prognosis 6  tfidf - nb  \n",
       "263999     Prognosis 6  tfidf - nb  \n",
       "\n",
       "[264000 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the generate_recall_table_prop function to generate a table with all recall values for all proportions\n",
    "df_prop_sizes = generate_recall_table_prop.generate_recall_table_prop(evaluation_sizes, proportions, n_simulations, data_type = 'adapted')\n",
    "\n",
    "# Adapt the review names\n",
    "df_prop_sizes['Review'] = df_prop_sizes.apply(lambda row: row['Review'] + '_' + str(row['Total records']) + '_' + str(row['Relevant records']), axis=1)\n",
    "\n",
    "df_prop_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a019d1",
   "metadata": {},
   "source": [
    "Calculate the maximum recall values that could be obtained at each of the proportions screened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe08fb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Maximum recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1_1000_0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1_1000_0.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1_1000_0.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1_1000_0.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1_1000_0.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Prog6_500_0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Prog6_500_0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Prog6_500_0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Prog6_500_0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Prog6_500_0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Review  Maximum recall\n",
       "0    Int1_1000_0.05             0.0\n",
       "1    Int1_1000_0.05             1.0\n",
       "2    Int1_1000_0.05             1.0\n",
       "3    Int1_1000_0.05             1.0\n",
       "4    Int1_1000_0.05             1.0\n",
       "..              ...             ...\n",
       "259   Prog6_500_0.1             1.0\n",
       "260   Prog6_500_0.1             1.0\n",
       "261   Prog6_500_0.1             1.0\n",
       "262   Prog6_500_0.1             1.0\n",
       "263   Prog6_500_0.1             1.0\n",
       "\n",
       "[264 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dictionary\n",
    "ss_dict_ord = collections.OrderedDict(sorted(ss_dict.items()))\n",
    "# Use the max_recall_prop function to calculate the maximum achievable recall for each review\n",
    "df_max_recalls_sizes = max_recall_prop.max_recall_prop(ss_dict_ord, proportions)\n",
    "df_max_recalls_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafd870",
   "metadata": {},
   "source": [
    "Create a raw table with the work-saved-over sampling, normalized work-saved-over sampling, workload reduction in number of records, and workload reduction in hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8889c673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Total records</th>\n",
       "      <th>Relevant records</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Query model</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>WSS@95%</th>\n",
       "      <th>n-WSS@95%</th>\n",
       "      <th>Workload reduction (n)</th>\n",
       "      <th>Workload reduction (hours)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>438</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>2</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>434</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>3</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.918182</td>\n",
       "      <td>426</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>4</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>428</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>5</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>438</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>196</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.559794</td>\n",
       "      <td>1108</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>197</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.528866</td>\n",
       "      <td>1048</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>198</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.556701</td>\n",
       "      <td>1102</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>199</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.559794</td>\n",
       "      <td>1108</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>200</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.558763</td>\n",
       "      <td>1106</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Review Seed Total records Relevant records Train model  \\\n",
       "0          Int1_500_0.1    1           500              0.1          nb   \n",
       "1          Int1_500_0.1    1           500              0.1          nb   \n",
       "2          Int1_500_0.1    1           500              0.1          nb   \n",
       "3          Int1_500_0.1    1           500              0.1          nb   \n",
       "4          Int1_500_0.1    1           500              0.1          nb   \n",
       "...                 ...  ...           ...              ...         ...   \n",
       "23995  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23996  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23997  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23998  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23999  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "\n",
       "      Feature model Query model  Simulation  WSS@95%  n-WSS@95%  \\\n",
       "0             tfidf         max           1    0.826   0.945455   \n",
       "1             tfidf         max           2    0.818   0.936364   \n",
       "2             tfidf         max           3    0.802   0.918182   \n",
       "3             tfidf         max           4    0.806   0.922727   \n",
       "4             tfidf         max           5    0.826   0.945455   \n",
       "...             ...         ...         ...      ...        ...   \n",
       "23995         tfidf         max         196    0.504   0.559794   \n",
       "23996         tfidf         max         197    0.474   0.528866   \n",
       "23997         tfidf         max         198    0.501   0.556701   \n",
       "23998         tfidf         max         199    0.504   0.559794   \n",
       "23999         tfidf         max         200    0.503   0.558763   \n",
       "\n",
       "       Workload reduction (n)  Workload reduction (hours)  \n",
       "0                         438                         3.6  \n",
       "1                         434                         3.6  \n",
       "2                         426                         3.6  \n",
       "3                         428                         3.6  \n",
       "4                         438                         3.6  \n",
       "...                       ...                         ...  \n",
       "23995                    1108                         9.2  \n",
       "23996                    1048                         8.7  \n",
       "23997                    1102                         9.2  \n",
       "23998                    1108                         9.2  \n",
       "23999                    1106                         9.2  \n",
       "\n",
       "[24000 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the generate_wss_table function to create a table with the workload metrics\n",
    "df_wss_sizes = generate_wss_table.generate_wss_table(evaluation_sizes, n_simulations, data_type = 'adapted')\n",
    "\n",
    "# Adapt the review names\n",
    "df_wss_sizes['Review'] = df_wss_sizes.apply(lambda row: row['Review'] + '_' + str(row['Total records']) + '_' + str(row['Relevant records']), axis=1)\n",
    "\n",
    "#df_wss_sizes.to_excel('results/table_wss_sizes.xlsx')\n",
    "\n",
    "df_wss_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4751ba4",
   "metadata": {},
   "source": [
    "Create a raw table with the precision metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19ab8c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Total records</th>\n",
       "      <th>Relevant records</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Query model</th>\n",
       "      <th>Simulation</th>\n",
       "      <th>Precision@95%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>2</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>3</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>4</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1_500_0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>5</td>\n",
       "      <td>0.596774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>196</td>\n",
       "      <td>0.041480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>197</td>\n",
       "      <td>0.039916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>198</td>\n",
       "      <td>0.042316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>199</td>\n",
       "      <td>0.041480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>Prog6_2000_0.025</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>max</td>\n",
       "      <td>200</td>\n",
       "      <td>0.042506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Review Seed Total records Relevant records Train model  \\\n",
       "0          Int1_500_0.1    1           500              0.1          nb   \n",
       "1          Int1_500_0.1    1           500              0.1          nb   \n",
       "2          Int1_500_0.1    1           500              0.1          nb   \n",
       "3          Int1_500_0.1    1           500              0.1          nb   \n",
       "4          Int1_500_0.1    1           500              0.1          nb   \n",
       "...                 ...  ...           ...              ...         ...   \n",
       "23995  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23996  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23997  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23998  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "23999  Prog6_2000_0.025    5          2000            0.025          nb   \n",
       "\n",
       "      Feature model Query model  Simulation  Precision@95%  \n",
       "0             tfidf         max           1       0.596774  \n",
       "1             tfidf         max           2       0.575758  \n",
       "2             tfidf         max           3       0.513514  \n",
       "3             tfidf         max           4       0.527778  \n",
       "4             tfidf         max           5       0.596774  \n",
       "...             ...         ...         ...            ...  \n",
       "23995         tfidf         max         196       0.041480  \n",
       "23996         tfidf         max         197       0.039916  \n",
       "23997         tfidf         max         198       0.042316  \n",
       "23998         tfidf         max         199       0.041480  \n",
       "23999         tfidf         max         200       0.042506  \n",
       "\n",
       "[24000 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output table for precision\n",
    "\n",
    "df_prec_sizes = pd.DataFrame()\n",
    "length = n_simulations\n",
    "for key, value in evaluation_sizes.items():\n",
    "    names = key.split('_')\n",
    "    review = [names[0]] * length\n",
    "    n_records = [names[1]] * length\n",
    "    rel_records = [names[2]] * length\n",
    "    train_model = [names[3]] * length\n",
    "    feature_model = [names[4]] * length\n",
    "    query_model = [names[5]] * length\n",
    "    seed = [names[6]] * length\n",
    "    simulations = range(1, n_simulations+1)\n",
    "    precision = value[0][4]['Precision'] ###\n",
    "    df_sim = pd.DataFrame(list(zip(review, seed, n_records, rel_records, train_model, feature_model, query_model, simulations, precision)),\n",
    "                           columns = ['Review', 'Seed', 'Total records', 'Relevant records', 'Train model', 'Feature model', 'Query model', 'Simulation', 'Precision@95%'])\n",
    "    df_prec_sizes = pd.concat([df_prec_sizes, df_sim])\n",
    "    \n",
    "    df_prec_sizes = df_prec_sizes.reset_index(drop = True)\n",
    "    \n",
    "df_prec_sizes['Review'] = df_prec_sizes.apply(lambda row: row['Review'] + '_' + str(row['Total records']) + '_' + str(row['Relevant records']), axis=1)\n",
    "\n",
    "df_prec_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb03ebb",
   "metadata": {},
   "source": [
    "### 13. Process raw tables into pooled tables (for results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7a8f2",
   "metadata": {},
   "source": [
    "Create a table with the results of wss/workload reduction and precision combined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be93a8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Total records</th>\n",
       "      <th>Relevant records</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>Mean_WSS95</th>\n",
       "      <th>ci95_hi_WSS95</th>\n",
       "      <th>ci95_lo_WSS95</th>\n",
       "      <th>Mean_nWSS95</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_prec95</th>\n",
       "      <th>ci95_hi_prec95</th>\n",
       "      <th>ci95_lo_prec95</th>\n",
       "      <th>Mean_workred_n</th>\n",
       "      <th>ci95_hi_workred_n</th>\n",
       "      <th>ci95_lo_workred_n</th>\n",
       "      <th>Mean_workred_hr</th>\n",
       "      <th>ci95_hi_workred_hr</th>\n",
       "      <th>ci95_lo_workred_hr</th>\n",
       "      <th>Models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.344</td>\n",
       "      <td>890</td>\n",
       "      <td>892</td>\n",
       "      <td>888</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.309</td>\n",
       "      <td>877</td>\n",
       "      <td>879</td>\n",
       "      <td>875</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.349</td>\n",
       "      <td>893</td>\n",
       "      <td>895</td>\n",
       "      <td>891</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.321</td>\n",
       "      <td>883</td>\n",
       "      <td>885</td>\n",
       "      <td>880</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.264</td>\n",
       "      <td>859</td>\n",
       "      <td>862</td>\n",
       "      <td>857</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>tfidf - nb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Review Seed Total records Relevant records Train model Feature model  \\\n",
       "0   Int1    1          1000             0.05          nb         tfidf   \n",
       "1   Int1    2          1000             0.05          nb         tfidf   \n",
       "2   Int1    3          1000             0.05          nb         tfidf   \n",
       "3   Int1    4          1000             0.05          nb         tfidf   \n",
       "4   Int1    5          1000             0.05          nb         tfidf   \n",
       "\n",
       "  Mean_WSS95 ci95_hi_WSS95 ci95_lo_WSS95 Mean_nWSS95  ... Mean_prec95  \\\n",
       "0      0.840         0.842         0.838       0.923  ...       0.350   \n",
       "1      0.827         0.829         0.825       0.910  ...       0.313   \n",
       "2      0.843         0.845         0.841       0.927  ...       0.354   \n",
       "3      0.833         0.835         0.830       0.916  ...       0.326   \n",
       "4      0.809         0.812         0.807       0.891  ...       0.269   \n",
       "\n",
       "  ci95_hi_prec95 ci95_lo_prec95 Mean_workred_n ci95_hi_workred_n  \\\n",
       "0          0.357          0.344            890               892   \n",
       "1          0.317          0.309            877               879   \n",
       "2          0.360          0.349            893               895   \n",
       "3          0.332          0.321            883               885   \n",
       "4          0.274          0.264            859               862   \n",
       "\n",
       "  ci95_lo_workred_n Mean_workred_hr ci95_hi_workred_hr ci95_lo_workred_hr  \\\n",
       "0               888             7.4                7.4                7.4   \n",
       "1               875             7.3                7.3                7.3   \n",
       "2               891             7.4                7.5                7.4   \n",
       "3               880             7.4                7.4                7.3   \n",
       "4               857             7.2                7.2                7.1   \n",
       "\n",
       "       Models  \n",
       "0  tfidf - nb  \n",
       "1  tfidf - nb  \n",
       "2  tfidf - nb  \n",
       "3  tfidf - nb  \n",
       "4  tfidf - nb  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wss_prec_all_values_sizes, df_wss_prec_sizes = generate_results_table.generate_results_table(df_wss_sizes, df_prec_sizes, data_type = 'adapted')\n",
    "df_wss_prec_all_values_sizes[['Review', 'Total records', 'Relevant records']] = df_wss_prec_all_values_sizes['Review'].str.split('_', expand=True)\n",
    "\n",
    "#df_wss_prec_sizes.to_excel('results/table_wss_precision_sizes.xlsx')\n",
    "df_wss_prec_all_values_sizes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "942a958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Total records</th>\n",
       "      <th>Relevant records</th>\n",
       "      <th>Train model</th>\n",
       "      <th>Feature model</th>\n",
       "      <th>WSS@95%recall (CI)</th>\n",
       "      <th>n-WSS@95%recall (CI)</th>\n",
       "      <th>Precision@95%recall (CI)</th>\n",
       "      <th>Workload reduction in record numbers (CI)</th>\n",
       "      <th>Workload reduction in hours (CI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Int1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.840 (0.838-0.842)</td>\n",
       "      <td>0.923 (0.921-0.926)</td>\n",
       "      <td>0.350 (0.344-0.357)</td>\n",
       "      <td>890 (888-892)</td>\n",
       "      <td>7.4 (7.4-7.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Int1</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.827 (0.825-0.829)</td>\n",
       "      <td>0.910 (0.908-0.912)</td>\n",
       "      <td>0.313 (0.309-0.317)</td>\n",
       "      <td>877 (875-879)</td>\n",
       "      <td>7.3 (7.3-7.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Int1</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.843 (0.841-0.845)</td>\n",
       "      <td>0.927 (0.925-0.929)</td>\n",
       "      <td>0.354 (0.349-0.360)</td>\n",
       "      <td>893 (891-895)</td>\n",
       "      <td>7.4 (7.4-7.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Int1</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.833 (0.830-0.835)</td>\n",
       "      <td>0.916 (0.913-0.918)</td>\n",
       "      <td>0.326 (0.321-0.332)</td>\n",
       "      <td>883 (880-885)</td>\n",
       "      <td>7.4 (7.3-7.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Int1</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.809 (0.807-0.812)</td>\n",
       "      <td>0.891 (0.888-0.893)</td>\n",
       "      <td>0.269 (0.264-0.274)</td>\n",
       "      <td>859 (857-862)</td>\n",
       "      <td>7.2 (7.1-7.2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Review Seed Total records Relevant records Train model Feature model  \\\n",
       "0   Int1    1          1000             0.05          nb         tfidf   \n",
       "1   Int1    2          1000             0.05          nb         tfidf   \n",
       "2   Int1    3          1000             0.05          nb         tfidf   \n",
       "3   Int1    4          1000             0.05          nb         tfidf   \n",
       "4   Int1    5          1000             0.05          nb         tfidf   \n",
       "\n",
       "    WSS@95%recall (CI) n-WSS@95%recall (CI) Precision@95%recall (CI)  \\\n",
       "0  0.840 (0.838-0.842)  0.923 (0.921-0.926)      0.350 (0.344-0.357)   \n",
       "1  0.827 (0.825-0.829)  0.910 (0.908-0.912)      0.313 (0.309-0.317)   \n",
       "2  0.843 (0.841-0.845)  0.927 (0.925-0.929)      0.354 (0.349-0.360)   \n",
       "3  0.833 (0.830-0.835)  0.916 (0.913-0.918)      0.326 (0.321-0.332)   \n",
       "4  0.809 (0.807-0.812)  0.891 (0.888-0.893)      0.269 (0.264-0.274)   \n",
       "\n",
       "  Workload reduction in record numbers (CI) Workload reduction in hours (CI)  \n",
       "0                             890 (888-892)                    7.4 (7.4-7.4)  \n",
       "1                             877 (875-879)                    7.3 (7.3-7.3)  \n",
       "2                             893 (891-895)                    7.4 (7.4-7.5)  \n",
       "3                             883 (880-885)                    7.4 (7.3-7.4)  \n",
       "4                             859 (857-862)                    7.2 (7.1-7.2)  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wss_prec_sizes[['Review', 'Total records', 'Relevant records']] = df_wss_prec_sizes['Review'].str.split('_', expand=True)\n",
    "df_wss_prec_sizes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2265d90",
   "metadata": {},
   "source": [
    "### 14. Create histograms for WSS and precision (for results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0e8c0",
   "metadata": {},
   "source": [
    "Replace the numbering in the output of the reviews since Prognosis review 5 is not included in our study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e3c02",
   "metadata": {},
   "source": [
    "Create histograms for (n-)WSS and precision for intervention and prognosis reviews seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6097d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histograms(dataset, x, variables, y_labels, review_types, hue = 'Models'):\n",
    "\n",
    "    dataset['Total records'] = dataset['Total records'].astype(pd.CategoricalDtype(categories=['500',\n",
    "                                                                                               '1000',\n",
    "                                                                                               '2000']))\n",
    "    \n",
    "    # Change dtype to numeric\n",
    "    for variable in variables:\n",
    "        dataset[variable] = pd.to_numeric(dataset[variable])\n",
    "        \n",
    "    # Create a histogram for each variable and review type\n",
    "    for i in range(0, len(variables)):\n",
    "        for j in review_types:\n",
    "            \n",
    "            sns.catplot(x=x, y=variables[i], hue=hue, palette='Blues', col = 'Total records', kind='bar',\n",
    "                        legend = False,\n",
    "                        data=dataset[dataset['Review'].str.startswith(j)]).set(ylabel=y_labels[i],ylim=(0,y_lims[i]))\n",
    "            plt.legend(fontsize='10', title_fontsize='14', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a3ab1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Choose variables to plot\n",
    "variables_to_plot = ['Mean_WSS95', 'Mean_nWSS95', 'Mean_prec95']\n",
    "variable_names = ['WSS@95', 'n-WSS@95', 'Precision@95%']\n",
    "y_lims = [1,1,0.5]\n",
    "review_types = ['Prog', 'Int']\n",
    "            \n",
    "generate_histograms(dataset=df_wss_prec_all_values_sizes, \n",
    "                    x='Review', \n",
    "                    variables=variables_to_plot, \n",
    "                    y_labels=variable_names, \n",
    "                    review_types=review_types, \n",
    "                    hue='Seed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb0bf7",
   "metadata": {},
   "source": [
    "### 15. Create lineplots of increasing recall during screening (for results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8d3ba",
   "metadata": {},
   "source": [
    "Create lineplots for all simulations (or any other subset of data/modeling methods):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56a10b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lineplots(df_prop_ed, df_max_recalls_ed, subset_reviews = None):\n",
    "    \n",
    "    # Select the subset from the dataframe containing all recall values for each proportion screened\n",
    "    df_lineplots = df_prop_ed.copy()\n",
    "    \n",
    "    df_lineplots['Models'] = df_lineplots['Models'].astype(pd.CategoricalDtype(categories=['tfidf - nb',\n",
    "                                                                  'tfidf - svm',\n",
    "                                                                  'tfidf - logistic',\n",
    "                                                                  'sbert - svm',\n",
    "                                                                  'sbert - logistic']))\n",
    "    \n",
    "    df_lineplots['Review_full'] = df_lineplots['Review_full'].astype(pd.CategoricalDtype(categories=['Prognosis 3',\n",
    "                                                                  'Prognosis 4',\n",
    "                                                                  'Prognosis 5',\n",
    "                                                                  'Prognosis 6',\n",
    "                                                                  'Intervention 1',\n",
    "                                                                  'Intervention 2',\n",
    "                                                                  'Intervention 4',\n",
    "                                                                  'Intervention 6']))\n",
    "    df_lineplots['Seed'] = 'Sample ' + df_lineplots['Seed'] \n",
    "    \n",
    "    if subset_reviews != None:\n",
    "        reviews = '|'.join(subset_reviews)\n",
    "        df_lineplots = df_lineplots[df_lineplots['Review'].str.contains(reviews, regex=True)]\n",
    "\n",
    "    # Create a figure with lineplots for each review-model combination seperately\n",
    "    p2 = sns.catplot(data = df_lineplots, kind = 'point', \n",
    "                     x = 'percentage of records screened', y = 'recall', \n",
    "                     col = 'Review_full', \n",
    "                     hue = 'Seed', \n",
    "                     errorbar = 'ci',\n",
    "                     palette = 'Blues',\n",
    "                     col_wrap = 2, aspect = 1.4, legend = False\n",
    "                     )\n",
    "\n",
    "    axes = p2.fig.axes\n",
    "\n",
    "    for i in range(0, len(df_lineplots['Review'].unique())):\n",
    "        max_recalls_per_prop = df_max_recalls_ed.loc[df_max_recalls_ed['Review'] == df_lineplots['Review'].unique()[i]]['Maximum recall']    \n",
    "        manual_screening = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "        x_axis = df_lineplots['percentage of records screened'][0:len(max_recalls_per_prop)]\n",
    "        axes[i].plot(x_axis, max_recalls_per_prop + 0.005, 'k-', linewidth = 1, color = 'grey', linestyle = '--', label = \"maximum recall\") \n",
    "        axes[i].plot(x_axis, manual_screening, 'k-', linewidth = 1, color = 'grey', linestyle = '-', label = \"manual screening\") \n",
    "        axes[i].legend(loc=\"lower right\", fontsize = 12.5)\n",
    "    \n",
    "    if subset_reviews[0] == 'Int8':\n",
    "        p2.set_titles('Intervention A1', size = 16, weight = 'bold')\n",
    "    else:\n",
    "        p2.set_titles(col_template = \"{col_name}\", size = 16, weight = 'bold')\n",
    "    p2.set_xlabels('Percentage of records screened', size = 16)\n",
    "    p2.set_ylabels('Recall', size = 16)\n",
    "    p2.set(ylim = (0, 1.01))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21be0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "subset_reviews = ['500']\n",
    "generate_lineplots(df_prop_sizes, df_max_recalls_sizes, subset_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb8c3c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "subset_reviews = ['1000']\n",
    "generate_lineplots(df_prop_sizes, df_max_recalls_sizes, subset_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b7282fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "subset_reviews = ['2000']\n",
    "generate_lineplots(df_prop_sizes, df_max_recalls_sizes, subset_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565045d",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
